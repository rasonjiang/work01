# work01
本工程使用Spark对模拟数据进行了分布式排序。分别使用了选择排序、归并排序、快速排序、希尔排序、基数排序
只需运行DistributedSort类中的main函数，即可进行排序。可根据需要对模拟数据量和排序方式进行调整
排序本身的复杂度与普通排序相同，但对于不同的排序方式，涉及到不同的数据分区和合并策略。
Spark本身自带的sortBy和sortByKey函数是基于快速排序，快速排序在分布式框架中对大规模数据的排序

关于分布式计算框架Spark：
Spark是一种分布式计算框架，不负责数据的存储和管理。因此通常会将Spark和Hadoop进行统一部署，由Hadoop中的HDFS、HBase等组件负责存储管理。
RDD：弹性分布式数据集（Resilient Distributed Datasets），是一个不可变的分布式对象集合。每个RDD分为多个分区，这些分区运行在集群中的不同节点上。RDD可以包含Python、Java、Scala中任意类型的对象，甚至自定义对象，用户可以使用两种方式创建RDD：读取外部数据集，或在驱动器程序里分发驱动器程序中的对象集合（如list和set）
 
 对于Spark，它本身就是设计为在分布式环境中运行，分布式环境会自动管理任务的划分、并行执行，充分利用集群的计算资源，不需要手动引入多线程。
Spark的RDD抽象允许开发者对数据进行并行操作，而Spark会在后台自动将这些操作分发到集群中的多个节点上执行。因此如果使用Spark进行分布式排序，只需要在应用程序中使用Spark提供的API（如sortBy或sortByKey等）进行排序操作，而不需要手动引入多线程。
